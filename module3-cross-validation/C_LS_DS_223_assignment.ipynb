{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.9"
    },
    "colab": {
      "name": "LS_DS_223_assignment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jduell12/DS-Unit-2-Kaggle-Challenge/blob/main/LS_DS_223_assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hnexT5_1Jvi"
      },
      "source": [
        "Lambda School Data Science\n",
        "\n",
        "*Unit 2, Sprint 2, Module 3*\n",
        "\n",
        "---\n",
        "<p style=\"padding: 10px; border: 2px solid red;\">\n",
        "    <b>Before you start:</b> Today is the day you should submit the dataset for your Unit 2 Build Week project. You can review the guidelines and make your submission in the Build Week course for your cohort on Canvas.</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtCG3mCr1Jvn"
      },
      "source": [
        "%%capture\n",
        "import sys\n",
        "\n",
        "# If you're on Colab:\n",
        "if 'google.colab' in sys.modules:\n",
        "    DATA_PATH = 'https://raw.githubusercontent.com/LambdaSchool/DS-Unit-2-Kaggle-Challenge/main/data/'\n",
        "    !pip install category_encoders==2.*\n",
        "    !pip install pandas-profiling==2.*\n",
        "\n",
        "# If you're working locally:\n",
        "else:\n",
        "    DATA_PATH = '../data/'"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBmXlHCf1Jvo"
      },
      "source": [
        "# Module Project: Hyperparameter Tuning\n",
        "\n",
        "This sprint, the module projects will focus on creating and improving a model for the Tanazania Water Pump dataset. Your goal is to create a model to predict whether a water pump is functional, non-functional, or needs repair.\n",
        "\n",
        "Dataset source: [DrivenData.org](https://www.drivendata.org/competitions/7/pump-it-up-data-mining-the-water-table/).\n",
        "\n",
        "## Directions\n",
        "\n",
        "The tasks for this project are as follows:\n",
        "\n",
        "- **Task 1:** Use `wrangle` function to import training and test data.\n",
        "- **Task 2:** Split training data into feature matrix `X` and target vector `y`.\n",
        "- **Task 3:** Establish the baseline accuracy score for your dataset.\n",
        "- **Task 4:** Build `clf_dt`.\n",
        "- **Task 5:** Build `clf_rf`.\n",
        "- **Task 6:** Evaluate classifiers using k-fold cross-validation.\n",
        "- **Task 7:** Tune hyperparameters for best performing classifier.\n",
        "- **Task 8:** Print out best score and params for model.\n",
        "- **Task 9:** Create `submission.csv` and upload to Kaggle.\n",
        "\n",
        "You should limit yourself to the following libraries for this project:\n",
        "\n",
        "- `category_encoders`\n",
        "- `matplotlib`\n",
        "- `pandas`\n",
        "- `pandas-profiling`\n",
        "- `sklearn`\n",
        "\n",
        "# I. Wrangle Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6jjhwsfsf78a",
        "outputId": "c2cde1b3-76e6-4b38-a076-cff958c6b276"
      },
      "source": [
        "from category_encoders import OrdinalEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.model_selection import cross_val_score #k-fold cross validation,\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV # hyperparameter fine tuning \n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2x46E5O1Jvp"
      },
      "source": [
        "def wrangle(fm_path, tv_path=None):\n",
        "    if tv_path:\n",
        "        df = pd.merge(pd.read_csv(fm_path, \n",
        "                                  na_values=[0, -2.000000e-08]),\n",
        "                      pd.read_csv(tv_path)).set_index('id')\n",
        "    else:\n",
        "        df = pd.read_csv(fm_path, \n",
        "                         na_values=[0, -2.000000e-08],\n",
        "                         index_col='id')\n",
        "\n",
        "    # Drop constant columns\n",
        "    df.drop(columns=['recorded_by'], inplace=True)\n",
        "\n",
        "    # Drop HCCCs\n",
        "    cutoff = 100\n",
        "    drop_cols = [col for col in df.select_dtypes('object').columns\n",
        "                 if df[col].nunique() > cutoff]\n",
        "    df.drop(columns=drop_cols, inplace=True)\n",
        "\n",
        "    # Drop duplicate columns\n",
        "    dupe_cols = [col for col in df.head(15).T.duplicated().index\n",
        "                 if df.head(15).T.duplicated()[col]]\n",
        "    df.drop(columns=dupe_cols, inplace=True)             \n",
        "\n",
        "    return df"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wE9mJ8sG1Jvq"
      },
      "source": [
        "**Task 1:** Using the above `wrangle` function to read `train_features.csv` and `train_labels.csv` into the DataFrame `df`, and `test_features.csv` into the DataFrame `X_test`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQOEQlQJ1Jvq"
      },
      "source": [
        "df = wrangle(DATA_PATH + 'waterpumps/train_features.csv', DATA_PATH + 'waterpumps/train_labels.csv')\n",
        "X_test = wrangle(DATA_PATH + 'waterpumps/test_features.csv')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PUR4iS-1Jvr"
      },
      "source": [
        "# II. Split Data\n",
        "\n",
        "**Task 2:** Split your DataFrame `df` into a feature matrix `X` and the target vector `y`. You want to predict `'status_group'`.\n",
        "\n",
        "**Note:** You won't need to do a train-test split because you'll use cross-validation instead."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0HYnfqJ1Jvs"
      },
      "source": [
        "target='status_group'\n",
        "X = df.drop(columns=target)\n",
        "y = df[target]"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-N5Xn6E1Jvs"
      },
      "source": [
        "# III. Establish Baseline\n",
        "\n",
        "**Task 3:** Since this is a **classification** problem, you should establish a baseline accuracy score. Figure out what is the majority class in `y_train` and what percentage of your training observations it represents."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yfCDvp2j1Jvt",
        "outputId": "6106c19b-eeb6-432b-f0f3-f1878f254e82"
      },
      "source": [
        "baseline_acc = y.value_counts(normalize=True).max()\n",
        "print('Baseline Accuracy Score:', baseline_acc)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline Accuracy Score: 0.5430899510092763\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVQFegu61Jvt"
      },
      "source": [
        "# IV. Build Models\n",
        "\n",
        "**Task 4:** Build a `Pipeline` named `clf_dt`. Your `Pipeline` should include:\n",
        "\n",
        "- an `OrdinalEncoder` transformer for categorical features.\n",
        "- a `SimpleImputer` transformer fot missing values.\n",
        "- a `DecisionTreeClassifier` Predictor.\n",
        "\n",
        "**Note:** Do not train `clf_dt`. You'll do that in a subsequent task. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-vOogNm1Jvu"
      },
      "source": [
        "clf_dt = make_pipeline(\n",
        "    OrdinalEncoder(),\n",
        "    SimpleImputer(),\n",
        "    DecisionTreeClassifier(random_state=42)\n",
        ")"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MACX-C5G1Jvu"
      },
      "source": [
        "**Task 5:** Build a `Pipeline` named `clf_rf`. Your `Pipeline` should include:\n",
        "\n",
        "- an `OrdinalEncoder` transformer for categorical features.\n",
        "- a `SimpleImputer` transformer fot missing values.\n",
        "- a `RandomForestClassifier` predictor.\n",
        "\n",
        "**Note:** Do not train `clf_rf`. You'll do that in a subsequent task. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvh-67kf1Jvu"
      },
      "source": [
        "clf_rf = make_pipeline(\n",
        "    OrdinalEncoder(),\n",
        "    SimpleImputer(),\n",
        "    RandomForestClassifier(random_state=42, n_estimators=25)\n",
        ")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2sJmnwu1Jvv"
      },
      "source": [
        "# V. Check Metrics\n",
        "\n",
        "**Task 6:** Evaluate the performance of both of your classifiers using k-fold cross-validation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4iDfwsF91Jvv"
      },
      "source": [
        "cv_scores_dt = cross_val_score(clf_dt, X, y, cv=5, n_jobs=-1)\n",
        "cv_scores_rf = cross_val_score(clf_rf, X, y, cv=5, n_jobs=-1)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYBmSk7o1Jvv",
        "outputId": "af9772da-031f-4123-c56b-76703daeafae"
      },
      "source": [
        "print('CV scores DecisionTreeClassifier')\n",
        "print(cv_scores_dt)\n",
        "print('Mean CV accuracy score:', cv_scores_dt.mean())\n",
        "print('STD CV accuracy score:', cv_scores_dt.std())"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CV scores DecisionTreeClassifier\n",
            "[0.75707071 0.74848485 0.75454545 0.7547138  0.75351461]\n",
            "Mean CV accuracy score: 0.7536658840842694\n",
            "STD CV accuracy score: 0.0028400921277755204\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LYCin9GR1Jvw",
        "outputId": "efcce747-7647-45f3-a64e-6acc3ee9f79c"
      },
      "source": [
        "print('CV score RandomForestClassifier')\n",
        "print(cv_scores_rf)\n",
        "print('Mean CV accuracy score:', cv_scores_rf.mean())\n",
        "print('STD CV accuracy score:', cv_scores_rf.std())"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CV score RandomForestClassifier\n",
            "[0.8047138  0.80016835 0.80572391 0.7973064  0.79695261]\n",
            "Mean CV accuracy score: 0.8009730126701253\n",
            "STD CV accuracy score: 0.003655673240336913\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4Oiip4S1Jvw"
      },
      "source": [
        "# VI. Tune Model\n",
        "\n",
        "**Task 7:** Choose the best performing of your two models and tune its hyperparameters using a `RandomizedSearchCV` named `model`. Make sure that you include cross-validation and that `n_iter` is set to at least `25`.\n",
        "\n",
        "**Note:** If you're not sure which hyperparameters to tune, check the notes from today's guided project and the `sklearn` documentation. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5O4jjrsT1Jvw"
      },
      "source": [
        "param_distribution = {\n",
        "    'simpleimputer__strategy': ['mean', 'median'],\n",
        "    'randomforestclassifier__max_depth': range(5, 40, 5),\n",
        "    'randomforestclassifier__n_estimators': range(25, 125, 25)\n",
        "}\n",
        "model = RandomizedSearchCV(\n",
        "    clf_rf,\n",
        "    param_distributions=param_distribution,\n",
        "    n_iter=10,\n",
        "    cv=5,\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qqILmSQgoGHw",
        "outputId": "91ca20dc-4dc1-4060-d4c4-8594701ec51f"
      },
      "source": [
        "model.fit(X, y)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  4.0min\n",
            "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  4.3min finished\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=5, error_score=nan,\n",
              "                   estimator=Pipeline(memory=None,\n",
              "                                      steps=[('ordinalencoder',\n",
              "                                              OrdinalEncoder(cols=None,\n",
              "                                                             drop_invariant=False,\n",
              "                                                             handle_missing='value',\n",
              "                                                             handle_unknown='value',\n",
              "                                                             mapping=None,\n",
              "                                                             return_df=True,\n",
              "                                                             verbose=0)),\n",
              "                                             ('simpleimputer',\n",
              "                                              SimpleImputer(add_indicator=False,\n",
              "                                                            copy=True,\n",
              "                                                            fill_value=None,\n",
              "                                                            missing_values=nan,\n",
              "                                                            strategy='mean',\n",
              "                                                            verbose=0)...\n",
              "                                                                     verbose=0,\n",
              "                                                                     warm_start=False))],\n",
              "                                      verbose=False),\n",
              "                   iid='deprecated', n_iter=10, n_jobs=-1,\n",
              "                   param_distributions={'randomforestclassifier__max_depth': range(5, 40, 5),\n",
              "                                        'randomforestclassifier__n_estimators': range(25, 125, 25),\n",
              "                                        'simpleimputer__strategy': ['mean',\n",
              "                                                                    'median']},\n",
              "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
              "                   return_train_score=False, scoring=None, verbose=1)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTTcSwOT1Jvw"
      },
      "source": [
        "**Task 8:** Print out the best score and best params for `model`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gE4zmp3R1Jvx",
        "outputId": "ab8099a1-6dc1-4114-ee9f-2126c2a9f9cb"
      },
      "source": [
        "best_score = model.best_score_\n",
        "best_params = model.best_params_\n",
        "\n",
        "print('Best score for `model`:', best_score)\n",
        "print('Best params for `model`:', best_params)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best score for `model`: 0.8073704721259229\n",
            "Best params for `model`: {'simpleimputer__strategy': 'mean', 'randomforestclassifier__n_estimators': 50, 'randomforestclassifier__max_depth': 20}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgd0WhgV1Jvx"
      },
      "source": [
        "# Communicate Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ug7KTL_Y1Jvx"
      },
      "source": [
        "**Task 9:** Create a DataFrame `submission` whose index is the same as `X_test` and that has one column `'status_group'` with your predictions. Next, save this DataFrame as a CSV file and upload your submissions to our competition site. \n",
        "\n",
        "**Note:** Check the `sample_submission.csv` file on the competition website to make sure your submissions follows the same formatting. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CY9fKZAP1Jvx"
      },
      "source": [
        "y_pred = model.predict(X_test)\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHU5PM7wptrQ"
      },
      "source": [
        "submission = pd.DataFrame(y_pred, index=X_test.index, columns=['status_group'])"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "B1gyvQDQpy6q",
        "outputId": "fbba98ee-e735-4eef-d539-15f5e23865ed"
      },
      "source": [
        "submission.head()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>status_group</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>50785</th>\n",
              "      <td>non functional</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51630</th>\n",
              "      <td>functional</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17168</th>\n",
              "      <td>functional</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45559</th>\n",
              "      <td>non functional</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49871</th>\n",
              "      <td>functional</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         status_group\n",
              "id                   \n",
              "50785  non functional\n",
              "51630      functional\n",
              "17168      functional\n",
              "45559  non functional\n",
              "49871      functional"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4nvSFkZpzyM"
      },
      "source": [
        "date_stamp = pd.Timestamp.now().strftime('%Y-%m-%d_%H-%M')\n",
        "submission.to_csv(f'{date_stamp}_submission.csv')"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKEwuzz7qFbn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}